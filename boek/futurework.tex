\chapter{Conclusion and Future Work}

%Our system only provides a snapshot of the expertise on a given time, it should be better if we could provide an overview in time.

\section{Conclusion}

In this master's thesis we examined the opportunities using the semantic web and data processing. We found out that the possibilities within expert finding and author disambiguation are challenging and can contribute in solving a real-life problem. At the end of this informative investigation, the objective became clear: creating a framework that is able to disambiguate authors and allows users to find experts for a certain subject, while keeping it extensible for future additions.

% Wat is juist zo naief aan de eerste aanpak en waarop is deze precies gebaseerd, in 1 zin

We started with a naive approach for the framework. We focused on what we knew and were comfortable with rather than the problem we had to solve. It lacked both in performance and scalability, while the usage of a relational database would render it unrealizable. Profound inspection of this first version of the framework, however, learned us that in order to create a good one, it would have to amplify the following five foundations:

\begin{enumerate}
	\item All instances are considered different authors until proven otherwise.
	\item No decision is made permanent.
	\item Any information is considered partial information.
	\item A constantly changing input asks for a constantly changing output.
	\item The stream of informaton is endless.
\end{enumerate}

% Iets over graaf en regels

With these foundations in mind, we first created a theoretical model. This model consists of three layers that integrate structural, informational and algorithmic aspects. It deals with the main difficulties of author disambiguation, while minimizing the problem domain and we explained how to process the (partial) information in order for similarities to be found. 

Rules drive the entire flow in our framework by converting novel facts into similarities that group instances with authors through clustering. The four rules we defined for our framework are:

\begin{enumerate}
	\item \textit{Community Rule} Exploiting the fact that authors often work together with the same co-author.
	\item \textit{Interest Rule} The subjects of publications of the same author are usually located within the same field of research.
	\item \textit{Email Rule} Authors with the same email address, are most likely the same person.
	\item \textit{Affiliation Rule} Authors are more likely to work at one affiliation at a given time.
\end{enumerate}

We implemented this theoretical model with pipes and filters using Ruby, Java, a key-value store Redis, Resque for scaling and the Tinkerpop stack for the graph representation. The usage of pipes and filters allows for modifiability. New pipes can easily be plugged into the flow which enables the convenient addition of extra information sources or new rules while the performance and scalability remain intact.

Clustering is the process that is responsible for grouping of authors based on the calculated similarities, a key component of our framework. We implemented the dynamic clustering algorithm proposed in \cite{saha2006dynamic} which is based on minimum-cut trees. The quality of the clusters is guaranteed to be the same as its static counterpart, while it is a lot faster as it considers much smaller subgraphs. We added an extra case to the proposed algorithm, exploiting the fact that our framework often has a succession of small similarities connecting the same clusters. This extra case permits the most resource-intensive case to be postponed and executed less frequently.

% Expert finding ?

% TODO precieze resultaat waarden invullen, gemiddelde waarde en vergelijking met dblp

We tested the framework thoroughly using a manually annotated testset of just over 1000 publications. We showed the impact of each of the rules on the accuracy, clarifying that the combination of all four of them render the best average results, although the increased accuracy from the addition of a rule is minimal in certain cases. We also examined the accuracy using different distributions for the rules and we noticed that the community rule had the biggest impact. Finally, we also compared the accuracy of our framework with the accuracy of DBLP for the tested authors and concluded that our framework transcends DBLP by $14\%$ or $17\%$, depending on how the mean accuracy is calculated.

\section{Future Work}

There are many possible additions to be made to the framework. Adding extra online sources by writing new pipes can help us in the search for more information about each author and give us a better view for disambiguation. Additional, extra rules could be written to translate the newly acquired information to similarities between authors which were previously unknown.

Another improvement is enabling the usage of negative weights for similarities. This could undo previously calculated results, when there is reason to believe two instances are not connected. Connected with these negative weights, would be the possibility to have immutable decisions. Especially if this decision is that two authors can never be the same. A simple reason that comes to mind is that they are both co-authors of the same publication.

Using an actual category tree containing a large overview of categories, could help in calculating more accurate similarities between keywords that are not the same, but are bound to the same area of expertise. This could also enable giving higher weights to keywords that are more specific for a certain subject.

Another addition would be using the abstract or even the actual text of the publication for deciding the category. This could get far better results are publication titles are sometimes vague and open for interpretation. Getting the abstract could be achieved by writing plugins for the most popular digital libriries by using web scraping.

% Rekening houden met negatieve gewichten
% Absolute vaststellingen kunnen maken : deze 2 auteurs zijn ZEKER verschillend en moeten altijd zo blijven
% Opstellen van categorie boom om betere keyword results te krijgen
% Grotere gewichten toekennen voor woorden die meer subject specifiek zijn
% Scalability fixen :o
% Meer bronnen opnemen
% Category bepaling niet enkel op basis van titel, maar ook abstract of zelfs volledige tekst => plugins schrijven voor verschillende paper aanbied sites (zijn er slechts een paar)
% 