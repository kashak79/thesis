\chapter{State of the art}

We examined a broad range of different topics with social media as central subject. It was an evolution starting from simple Twitter-related subjects to a full-fledged problem assignment many people struggle with. The journey towards this problem is interesting enough to devote a full thesis to in itself, but we will spare you the details and cover it in this chapter.

\section{Opinion mining}

\subsection{Introduction}
\label{general - opinion mining}
Opinion mining is part of the general area of \textit{sentiment analysis, opinion extraction or opinion mining and feature-based opinion summarization} from the user-generated content or user-generated media on the Web. The applications are manifold with the most important ones in the area of in business intelligence. 

Large companies receive thousands of pieces of feedback on a daily basis, both direct as indirect. Examples are online customer reviews, customer feedback, survey responses, social media messages, blogposts and comments. Human processing of such text volumes is prohibitively expensive and close to impossible. The only alternative is automatic extraction of relevant information. Ideally one would like to be able to quickly and cheaply customize a system to provide reasonably accurate sentiment classification for a domain, a brand or a specific product.

\subsection{Current situation}

%Sentiment360, lots of papers and onderzoek, really to much to name and to add something of importance.

\subsection{Improvements and additions}
We are looking into the analysis of social media messages, more specifically Twitter messages. We want to use Google's new service, Google Prediction API, which provides pattern-matching and machine learning capabilities. We can compare the results with one or more of the many papers and see if there is any added value in using this service.

We need a lot of training data in order for the Prediction API to learn likely future outcomes. As this service decides what algorithms it uses, there is a lack of possible research to make an interesting thesis.


%Zeer veel onderzoek en bestaande tools, mogelijke uitbreidingen zijn beperkt en toepassingen ook.

%\subsection{Bijlage}
%http://code.google.com/intl/nl-NL/apis/predict/

\section{Twitter influencers}

\subsection{Introduction}
As discussed in \ref{general - opinion mining} about opinion mining, people talk about products, both positive as negative. They have the ability to influence the buying behavior of others who respect their opinion about a certain area. Identifying these influencers can be of great value, for instance in the advertising industry.

\subsection{Current situation}
There are two main aspects, reach and trust. A person's reach determines the number of people who listen when he has something of value to say. Trust or influence depicts the value people give a certain person's opinion. Both aspects can vary a lot when comparing different topics for the same person.\\
There are papers discussing algorithms to find the ideal subset of individuals which will trigger a large cascade of conversions and papers researching the more general economic issues regarding influencers.\\
Also regarding the second aspect, trust, there are a lot of well documented scientific results. \footnote{Propagation Models for Trust and Distrust in Social Networks} describes propagation models which can be used to present trust and distrust in social networks. Just as in \footnote{Inferring Trust Relationships in Web-based Social Networks} an algorithm for calculating a trust metric is presented based on the EigenTrust algorithm\footnote{The eigentrust algorithm for reputation management in p2p networks, Kamvar 2003}.\\
The amount of applications focusing on calculating social media influence, as their core business or a useful option, is growing rapidly. Following is a short summary a few better applications.\\
Klout is a well-known online tool focusing on ranking Twitter profiles (and recently also Facebook profiles) using over 35 variables. These rankings are, though fun, not particularly useful as finding influencers based on topic is very limited, however there are interesting third-party applications providing this feature.\\
PeerIndex and Traackr focus more on identifying topics. Just like Klout, PeerIndex focuses on Twitter profiles and parameters captured from Twitter to assign a certain score to each profile. Traackr on the other hand uses data from multiple online sources connected to the users such as their blog, YouTube channel, LinkedIn and Twitter profile and more. Traackr combines the results and provides a three-way score (reach, relevance and resonance) based on a certain topic together with detailed contact information.

\subsection{Improvements and additions}
We want to start from a Twitter profile and find out more about a user using other social media networks, semantic databases and social graphs, comparable to Traackr.

\section{Event detection}

\subsection{General problem statement}


\subsection{Current situation}

\subsection{Improvements and additions}


\section{Expert Finding}

%Te bespreken: neo4j, Tinkerpop, Gremlin, Stanford POS tagger, lemmatizer, doc split (ruby gem), resque (ruby library - https://github.com/defunkt/resque), max flow :: min-cut

\subsection{Introduction}

Finding experts is useful for seeking consultants, collaborators or speakers. It is also of great value within the academic world as it provides a source of information to supplement or complement papers and theses. Many researchers and reporters lose a lot of time doing this manually as the amount of sources is ever growing: documents, email, databases, conferences, scientific papers and so on. The topic is luckily seeing an increase in attention in recent years.
%Expert finding is a difficult task requiring a multitude of different steps in order to find results bearing certain value. There are databases containing records of people matched with their area of expertise, which can be queried for a nominal fee, mostly used by reporters. The data has been gathered manually over time. To receive a more up-to-date or specific result, one will have to send a separate request which will come with a higher price and take its time.\\
%Another option is to do it manually. There are several steps which can be undertaken and they can be executed in fashionable order, repeated as often as necessary. One can search for conference sites about the topic and look up the names of the speakers. Current and past working experience can possibly be found on LinkedIn. Publications and co-authors can be retrieved from online databases with dedicated research publications or from more general databases such as Google Scholar. The authors and papers can be interlinked in order to see who works with who and who is most often cited or referenced. Influence can be measured on social media.\\
%It is clearly a lengthy process.

\subsection{Current situation}

\footnote{Balog, K. and Rijke, M.: Finding Experts and Their Details in E-mail Corpora. In Proceedings
of the 15th International Conference on World Wide Web (2006)} proposed four simple binary association methods to find expertise information from emails. \footnote{5} investigated the expertise of users and experts by combining information retrieval techniques. Both these solutions are insufficient for topic-based expert finding as their datasets (emails and online communities) are too limited, they focus too much on previous encounters and lack context.\\
\footnote{6} retrieves experts based on the amount of documents persons have for a given topic. As input a keyword phrase is used in order to find relevant documents. The results are however unsatisfactory caused by its slow response time and incorrect relationship between persons and documents. \footnote{8} gets better results using an algorithm based on a PageRank for document authority, a co-occurrence model for authors and multiple levels of associations between experts and topics. It succeeds to map variants of experts' names on the same author, but fails to identify different authors with the same name.\\
\footnote{Finding Topic-centric Identified Experts based on Full Text Analysis} proposes OntoFrame. It is an information service platforum using Semantic Web technologies and is based on an extensive ontology of 16 classes using RDF triples. Identity resolution and full text analysis forms the basis of their expert-finding method. The framework looks promising, however the prototype does not function \footnote{$http://ontoframe.kr/2008/2008_new/main.jsp$}.

\subsection{Improvements and additions}
We want to continue the research proposed in \footnote{Finding Topic-centric ...}, but less focused towards the full text analysis of documents. We want to combine multiple online sources, written as plugins, in order to achieve more information about experts, positiviely influencing the outcome of the algorithm.

%\subsection{What do we need}

