\chapter{Clustering Algorithm}

In this chapter we describe the clustering process, one of the core components of our framework. This process is responsible for deciding which nodes match to the same author, based on similarities between these nodes. These similarities are calculated by the different rules (see \autoref{rules}) that are implemented in our framework. Every time a new similarity is available, it is possible we have to recluster, meaning the grouping of the authors will be altered.

We need an efficient algorithm for clustering as it has to be able to handle a steady stream of new information while maintaining an optimal solution. The quality of this algorithm will make or break the quality of the output of our framework.

The algorithm we clarify in this chapter, is largely based on the algorithm described in \cite{saha2006dynamic}. It is an efficient, dynamic algorithm for clustering graphs handling insertion and deletion of edges while maintaining high quality clusters as defined by the quality requirement given in \cite{flake2004graph}. The algorithm makes heavy use of the minimum-cut tree. We implemented Gusfield's algorithm, based on \cite{rodrigues2011mpi}, and will explain this first.

The main feature of this dynamic algorithm is that it only builds part of the minimum-cut tree as and when necessary. The tree is computed over a subset of nodes, limited to a number of clusters. In our graph there might be an immense amount of authors, and thus clusters. However, the amount of authors involved with one change is limited. By just computing the clusters of this coarsened graph we can obtain the clusters of the original graph. These two properties are the reason the algorithm is efficient while maintaining an identical cluster quality as the static version described in \autoref{staticcutclustering}. Formal proof for the efficiency of this algorithm and the quality of the clusters can be found in \cite{saha2006dynamic}.

\section{Minimum-Cut Tree Algorithm}
\label{minimumcuttree}

\begin{algorithm}
\caption{Sequential Gusfield's Algorithm}
\label{mincutgusfield}
\begin{algorithmic}
\STATE \textbf{Input:} $G = (V,E,w)$ 
\STATE \textbf{Output:} $T = (V,E,f)$, where T is a cut tree of G
\STATE $V(T) \leftarrow V(G); E(T) \leftarrow \emptyset$
\FOR{$tree_i, flow_i, 1 \leq i \leq N$}
\STATE $tree_i \leftarrow 1; flow_i \leftarrow 0$
\ENDFOR
\STATE // $n - 1$ maximum flow iterations
\FOR{$s \leftarrow 2 $to$ N$}
\STATE $flow_s \leftarrow $MaxFlow$(s, tree_s)$
\STATE // adjust the $tree$ with Cut($s,tree_s$)
\STATE // c1 contains s and connected nodes, c2 contains $tree_s$ and connected nodes
	\FOR{$t \leftarrow 1 $ to $ N$}
		\IF{$t == s \vee t == tree_s$}
			\STATE next
		\ELSIF{$t \in c1 \wedge s \in c2$}
			\STATE $tree_t \leftarrow s$
		\ELSIF{$t \in c2 \wedge s \in c1$}
			\STATE $tree_t \leftarrow tree_s$
		\ENDIF
	\ENDFOR
\ENDFOR
\STATE // Generate T
\FOR{$s \leftarrow 1 $ to $ N$}
\STATE $E(T) \leftarrow E(T) \cup {s, tree_s}$
\STATE $f({s,tree_s}) \leftarrow flow_s$
\ENDFOR
\RETURN T
\end{algorithmic}
\end{algorithm}

% Perhaps this first paragraph should be moved to the SOTA

We briefly explain what is understood under a minimum cut tree, as clarified in \cite{saha2006dynamic}. 

Let $G = (V,E,w)$ denote a weighted undirected graph with $n = |V|$ nodes or vertices and $m = |E|$ links or edges. Each edge $e = (u, v), u,v \in V$ has an associated weight $w(u,v) > 0$. Let $s$ and $t$ be two nodes in $G(V,E)$, the source and destination. The minimum-cut of G with respect to $s$ and $t$ is a partition of $V$ which we will call $S$ and $V/S$. These partitions should be such that $s \in S, t \in V/S$ and the total weight of the edges linking nodes between the two partitions is minimum. The sum of these weights is called the cut-value and is denoted as $c(S,V/S)$. 

The minimum cut tree is a tree on $V$ such that inspecting the path between $s$ and $t$ in the tree, the minimum-cut of $G$ with respect of $s$ and $t$ can be obtained. Removal of the minimum weight edge in the path yields the two partitions and the weight of the corresponding edge gives the cut-value.

We implemented a sequential version of Gusfield's algorithm which calculates the minimum cut tree of any given graph. The pseudocode is given by \autoref{mincutgusfield}. In the pseudocode we use numbers to point to nodes or vertices. These numbers can be chosen randomly.

The algorithm consists of $n-1$ iterations of a Maximum Flow algorithm and for every iteration a different vertex is chosen as source. The destination vertex is determined by previous iterations and is saved in the tree. Initially all vertices of the output tree point to node 1, but this can be adjusted after each iteration. This adjustment depends on the minimum-cut between the current source and destination. We split all the nodes in two collections, using this minimum-cut. We adjust the parent of each node if it is on another side as its current parent, which is stored in the tree.

We choose an implementation of the Edmonds-Karp algorithm to find the maximum flow and the minimum-cut. This algorithm is an implementation of the Ford-Fulkerson method for computing the maximum flow and is provided to us through the Java library JUNG.

\section{Cut Clustering}

\cite{flake2004graph} defines a static algorithm for clustering based on minimum cut trees. \autoref{staticcutclustering} gives the pseudocode of the basic cut clustering algorithm. It adds an artificial sink $t$ to all the vertices of the graph with weight $\alpha > 0$. The minimum cut tree is computed using this new graph and the disjoint components obtained after removing the artificial vertex $t$, are the required clusters.

\begin{algorithm}
\caption{Static Cut Clustering Algorithm of \cite{flake2004graph}}
\label{staticcutclustering}
\begin{algorithmic}
\STATE \textbf{Input:} $G = (V,E,c), \alpha$ 
\STATE \textbf{Output:} Cluster of G
\STATE $V \leftarrow V \cup t$
\FOR{all vertices $v$ in G}
	\STATE Connect $t$ to $v$ with edge of weight $\alpha$
\ENDFOR
\STATE $G'(V',E') \leftarrow$ new graph after connecting t to V
\STATE Calculate the minimum-cut tree $T'$ of $G'$
\STATE Remove $t$ from T
\RETURN All connected components as clusters of G
\end{algorithmic}
\end{algorithm}

In \cite{saha2006dynamic}, they have extended this basic algorithm allowing it to work efficiently on dynamic graphs. They use some important new components which we also will use throughout the explanation of the algorithm. The adjacency matrix $A$ of $G$ is an $n \times n$ matrix in which $A(i,j) = w(i,j)$ if $(i,j) \in E$, else $A(i,j) = 0$. The algorithm also maintains two new variables for every vertex, the In Cluster Weight (ICW) and the Out Cluster Weigh (OCW). If $C_1,C_2,...C_s$ are the clusters of $G(V,E)$ then ICW and OCW are defined as below.

\begin{mydef}
\textbf{In Cluster Weight (ICW)} of a vertex $v \in V$ is defined as the total weight of the edges linking the vertex $v$ to all the vertices which belong to the same cluster as $v$. That is, if $v \in C_i$, $0 \leq i \leq s$ then $ICW(v) = \sum_{u \in C_i}{w(v,u)}$
\end{mydef}

\begin{mydef}
\textbf{Out Cluster Weight (OCW)} of a vertex $v \in V$ is defined as the total weight of the edges linking the vertex $v$ to all the vertices which do not belong to the same cluster as $v$. That is, if $v \in C_i$, $0 \leq i \leq s$ then $OCW(v) = \sum_{u \in C_j, j \neq i}{w(v,u)}$
\end{mydef}

A similarity between two instances is represented as a new edge between two nodes with a given weight. Using this weight, the probability that two instances belong to the same author can be derived. This weight is calculated by the rules in the disambiguator. There are two different possibilities that have to be treated separately: inter- and intra-cluster edge addition.

We assume we have $C = {C_1,C_2...C_s}$ as the clusters of the graph $G(V,E)$ which have been calculated in previous steps. We denote $A$ as the adjacency matrix of $G$.

\subsection{Intra-Cluster Edge Addition}

Intra-cluster edge addition means that both the nodes of the added edge belong to the same cluster. The result is that the cluster becomes stronger connected. We only have to update the $ICW$ and the adjacency matrix $A$ while the nodes remain unchanged. \autoref{intracluster} shows the pseudocode.

\begin{algorithm}
\caption{Intra-cluster edge addition between nodes $i$ and $j$ with weight $w(i,j)$}
\label{intracluster}
\begin{algorithmic}
\STATE \textbf{Input:} $G(V,E), (i,j), w(i,j)$ 
\STATE \textbf{Output:} Clusters of G
\STATE $A(i,j) \leftarrow A(i,j) + w(i,j)$
\STATE $ICW(i) \leftarrow ICW(i) + w(i,j)$
\STATE $ICW(j) \leftarrow ICW(j) + w(i,j)$
\RETURN $C$
\end{algorithmic}
\end{algorithm}

\subsection{Inter-Cluster Edge Addition}

Addition of an edge whose end nodes belong to different clusters is more challenging as it increases the connectivity across different clusters. This means the cluster quality of the clusters involved is lowered and as a result reclustering might be necessary when the quality is no longer maintained. 

There are three identifiable cases:

\begin{enumerate}
	\item \textbf{CASE 1} The addition of the edge does not break the clusters involved.
	\item \textbf{CASE 2} The addition of the edge causes the clusters to be so well connected that they are merged into one.
	\item \textbf{CASE 3} The new edge deteriorates the cluster quality and the nodes in both the clusters have to be reclustered.
\end{enumerate}

In each of these three cases, the addition of the new edge results in updating the adjacency matrix $A$ and the Outer Cluster Weight of the nodes involved. This is described in \autoref{updatevalues}. In order to understand the complete algorithm, we first need to explain two used processes: merging and contracting of clusters.

\begin{algorithm}
\caption{Updating the adjacency matrix $A$ and the Outer Cluster Weight: UPDATE($(i,j),w(i,j)$)}
\label{updatevalues}
\begin{algorithmic}
\STATE \textbf{Input:} Edge $(i,j)$ and weight $w(i,j)$
\STATE $A(i,j) \leftarrow A(i,j) + w(i,j)$
\STATE $OCW(i) \leftarrow OCW(i) + w(i,j)$
\STATE $OCW(j) \leftarrow OCW(j) + w(i,j)$
\end{algorithmic}
\end{algorithm}

\paragraph{Merging of Clusters} occurs in CASE 2 and is described in \autoref{merging}. Two clusters $C_u$ and $C_v$ are merged into one new cluster containing the nodes of the two original clusters. This causes the ICW of all the nodes involved to increase and the OCW to decrease as all the nodes are now more connected.

\begin{algorithm}
\caption{Merging of clusters $C_u$ and $C_v$: MERGE($C_u,C_v$)}
\label{merging}
\begin{algorithmic}
\STATE \textbf{Input:} $C_u$ and $C_v$ 
\STATE \textbf{Output:} Merged cluster
\STATE $D \leftarrow C_u \cup C_v$
\FOR{$\forall u \in C_u$}
	\STATE $ICW(u) \leftarrow ICW(u) + \sum_{v \in C_v}{w(u,v)}$
	\STATE $OCW(u) \leftarrow OCW(u) - \sum_{v \in C_v}{w(u,v)}$
\ENDFOR
\FOR{$\forall v \in C_v$}
	\STATE $ICW(v) \leftarrow ICW(v) + \sum_{u \in C_u}{w(v,u)}$
	\STATE $OCW(v) \leftarrow OCW(v) - \sum_{u \in C_u}{w(v,u)}$
\ENDFOR
\RETURN $D$
\end{algorithmic}
\end{algorithm}

\paragraph{Contraction of Clusters} occurs in CASE 3 as part of the reclustering process and is shown in \autoref{contracting}. All the nodes outside the set of clusters $S$ are replaced by a single new node $x$. Self loops that are created in this process are removed and parallel edges are replaced by a single edge with weight equal to the sum of the parallel edges. The reason we consider the clusters outside $S$ is because $S$ will generally be small while the other clusters will contain a lot of nodes.

\begin{algorithm}
\caption{Contraction of clusters outside the set of clusters $S$: CONTRACT($G(V,E),S)$)}
\label{contracting}
\begin{algorithmic}
\STATE \textbf{Input:} $G(V,E)$ and set of clusters $S$ 
\STATE \textbf{Output:} Contracted graph $G'(V',E')$
\STATE Add all vertices of $S$ to a new graph $G'$
\STATE $\forall i,j \in V' : A'(i,j) \leftarrow A(i,j)$
\STATE Add a new vertex $x$ to $G'$
\FOR{$\forall i \in \left\{V' - x\right\}$}
	\STATE $A'(i,x) = ICW(i) + OCW(i) - \sum_{j \in \left\{ V' - x \right\} }{A'(i,j)}$
\ENDFOR
\STATE Obtain $E'$ from $A'$
\RETURN $G'(V',E')$
\end{algorithmic}
\end{algorithm}

The complete algorithm for the addition of an edge between nodes that are contained in different clusters, is shown in \autoref{intercluster}. If the addition of the new edge does not deteriorate the clustering quality (CASE 1), the clusters are maintained and we only have to update the adjacency matrix $A$ and the Outer Cluster Weight of the nodes involved. 

If the hypothetical cluster quality of the cluster created by the combination of the two current clusters exceeds the threshold $\alpha$ (CASE 2), the clusters can be merged. 

Otherwise (CASE 3), we create a new, coarsened graph by contracting all the clusters except $C_u$ and $C_v$ to a node $x$. The resulting graph is significantly smaller than the original graph, resulting in lower execution times. Similarly as in \autoref{staticcutclustering}, we add an artificial sink $t$ to the coarsened graph. After adding edges between $t$ and the other nodes, we calculate the minimum-cut tree, as described in \autoref{minimumcuttree}. The connected components are computed from the resulting tree, after removing $t$. The components containing vertices of $C_u$ and $C_v$ along with the clusters $C-\left\{C_v,C_u\right\}$ are returned as the new clusters of the original graph. As a result of the reclustering, we have to recalculate the ICW and OCW of the nodes involved. This can easily be done by comparing the nodes in the old cluster and the nodes in the new cluster for each node.

\begin{algorithm}
\caption{Inter-cluster edge addition between nodes $i$ and $j$ with weight $w(i,j)$}
\label{intercluster}
\begin{algorithmic}
\STATE \textbf{Input:} $G(V,E), (i,j), w(i,j)$ and $\alpha$ 
\STATE \textbf{Output:} Clusters of $G$
\STATE $i \in C_u$ and $j \in C_v$
\IF{$\frac{\sum_{u \in C_u}{OCW(u) + w(i,j)}}{\left|V - C_u\right|} \leq \alpha \wedge \frac{\sum_{v \in C_v}{OCW(v) + w(i,j)}}{\left|V - C_v\right|} \leq \alpha$}
	\STATE // CASE 1
	\STATE $UPDATE((i,j),w(i,j))$
	\RETURN $C$
\ELSIF{$\frac{2 * c(C_u,C_v)}{V} \geq \alpha$}
	\STATE // CASE 2
	\STATE $UPDATE((i,j),w(i,j))$
	\STATE $D \leftarrow MERGE(C_u,C_v)$
	\RETURN $C + D - \left\{C_u,C_v\right\}$
\ELSE
	\STATE // CASE 3
	\STATE $UPDATE((i,j),w(i,j))$
	\STATE $G'(V',E') \leftarrow CONTRACT(G(V,E),\left\{C_u,C_v\right\} )$
	\STATE Connect $t$ to $v, \forall v \in C_u,C_v$ with edge of weight $\alpha$
	\STATE Connect $t$ to $V' - \left\{C_u, C_v\right\}$ with edge of weight $\alpha * \left| V - C_u - C_v \right|$
	\STATE G''(V'',E'') is the graph resulting in connecting $t$
	\STATE Calculate minimum-cut tree $T''$ of $G''(V'',E'')$
	\STATE Remove $t$
	\STATE // $\left\{D_1,D_2...D_k\right\}, k > 0$, are the connected components of $T''$ after removing $t$
	\STATE $C \leftarrow \left\{D_1,D_2...D_k,C_1,C_2...C_s\right\} - \left\{ C_u,C_v \right\}$
	\STATE // Update OCW and ICW using the new clusters
	\FOR{$\forall i \in C_u \cup C_v$}
		\STATE $sum \leftarrow \sum_{j \in old~neighbours}{A(i,j)}$
		\STATE $sum \leftarrow sum - \sum_{j \in new~neighbours}{A(i,j)}$
		\STATE $ICW(i) \leftarrow ICW(i) + sum$
		\STATE $OCW(i) \leftarrow OCW(i) - sum$
	\ENDFOR
	\RETURN $C$
\ENDIF
\end{algorithmic}
\end{algorithm}

We have a lot of rules resulting in small similarities, often following up on each other. This means we often will add edges will low weights. When testing the framework, we noticed that the clustering process often had to evaluate case 3 repeatedly, while the output did not result in reclustering. As case 3 is very time-intensive, especially when the clusters are getting bigger, we added an extra case in between case 1 and 2 based on the formula used to evaluate case 2. If $\frac{2 * c(C_u,C_v)}{V} \leq \alpha / 2$, we essentially fall back to case 1. This does not deteriorate the cluster quality.

% TODO moeten we hier nog vermelden hoe we dit precies geimplementeerd hebben ? Namelijk combinatie van Ruby, Java en Resque ? Misschien ook de voordelen aanhalen van deze aanpak tov andere mogelijke manieren of toch uitleggen waarom we hiervoor gekozen hebben ..
