\chapter{The framework}
\label{framework}

\section{Main Scenario}

The goal is to build a platform that allows a user to query for experts in a particular domain. The platform extracts and unifies the required information from a variety of online sources and subsequently builds a repository of user profiles. We basically want to create a framework that would function as a Google for finding experts given a certain subject.

We will use the following steps to build such a platform:

%verduidelijken dat de volgorde van deze stappen niet belangrijk is, ze zijn interchangeable

\begin{itemize}
	%Welke auteur namen ? Waar halen we die vandaan ? Conference sites ?
	\item \textbf{Seed data} We need a list of author names to start with.
	\item \textbf{Information extraction}
		\begin{itemize}
			\item Looking up personal information, for instance profiles from LinkedIn.
			\item Looking up publications, extracting title, co-authors and affiliation. The co-authors can be used as new input for further information extraction.
			\item Categorize publications by subject
		\end{itemize}
	\item \textbf{Disambiguation} Each name is represented as a single entity. In this step we search for similarities between these entities to decide which publications belong to the same author.
\end{itemize}

\section{Features}

Based on the main scenario, we can identify a few key features our framework will need. A short summarization of each follows, explaining the challenges we face with our thesis.

\subsection{Information extraction}

We need to extract information from multiple sources, which we will accomplish by using a plugin system. Each plugin is responsible for one source and will extract specific information which can be used by other plugins or other steps in our framework.

\subsection{Categorization}

In order to decide who is an expert regarding a certain subject, we will have to decide the subject of expertise of each author. A very important part of this will be in deciding the subject of the publications. The challenge is to decide this using as few information as possible, preferably by just inspecting the title, as getting access to the text of the publication itself is a whole lot more time- and resource-consuming.

\subsection{Disambiguation}

The most challenging feature is the disambiguation. There are two reasons. The first is the fact that an author's name is not a unique reference for a person. There might be multiple authors with the same name, which means we have to take this into account when deciding who is an expert. Secondly, a name might be spelled differently or changed throughout time. Examples are abbreviations, an extra family name because of a marriage or simply spelling errors.

\subsection{Dynamic}

There is a big dynamic concept tied to our thesis. People who are experts on a certain subject a decade ago, may not be as important anymore now or may have changed their subject of expertise. The framework should allow new information to be processed at any time and update the expertise of authors on the flow.

\section{Architecture}

Based on the scenario and the described features, we came up with the necessary components our framework needs. \autoref{fig:architectuur} shows a simplistic version of how the architecture will look like. The different components of the framework and their connection toward each other is displayed. In the next sections, the most important components will be explained at large.

\begin{figure}[htb]
	\centering
		\includegraphics[width=0.75\textwidth]{fig/architectuur}
	\caption{First attempt at the architecture based on the necessary components}
	\label{fig:architectuur}
\end{figure}

\subsection{Iteration Manager}

This component is responsible for the coordination of the flow in the entire framework. It knows what iteration our program is at and knows what the next steps are. It calls the necessary components and hands it the correct parameters in order for it to execute its code. This will become clearer when we explain the next components.

\subsection{Data Collector}

The Data Collector receives sources from the Source Generator. Each source describes the job to collect a particular piece of information. It will call each of its plugins with the parameters received from the Iteration Manager, updating the database with the new data the plugins will generate.

\subsection{Source Generator}

At each iteration step, the source generator examines the current data set and decides which paths have to be investigated in terms of sources.

\subsection{Category Builder}
\label{categorybuilder}

The Category Builder's role is deciding the subject(s) of the publications and assigning it to a category which fits in a category tree.

We have two main possibilities to decide the subject of a publication. The first is by only focusing on the publication title, the second is by also making use of the actual text in the publication. The second will yield us with better results, but getting the text and analyzing it will take a lot more time than just analyzing a few words. 

For both ways in deciding the subject, we will make use of the Stanford Part-of-speech Tagger. We use it to select the adjectives and nouns, as these contain the most interesting information regarding to deciding the field of the publication.

When only having the publication title, the words marked by the Stanford POS Tagger will be searched on Wikipedia, by use of the API. We will search for the words separately and make combinations, based on the closeness of the words in their original context.

When we have the original text of the publication, the easiest method is scanning for the keywords. These are often cited after the abstract and give us a very quick enumeration of the subjects discussed in the article. Another possibility is parsing the abstract itself by using the same algorithm explained above, used on the publication title.


\subsection{Disambiguator}
\label{disambiguator}

The disambiguation is an important factor towards the strength of our framework. In the data collection phase, we save each name as a new object in our database, even if that name is already stored. This is necessary to keep the option open that the same name might be connected towards different authors. This also means our database grows fast. 

The disambiguation exists out of a number of rules. These inspect several objects in the database and define the probabilities that names, typically connected to a publication or a profile, are connected to each other and to one author.

\subsection{Data Merger}

The Data Merger is responsible for merging the names together from time to time so they would reference to the same author. This component uses the probabilities calculated by the Disambiguator in order to do so.

\subsection{Data Layer and Database}

